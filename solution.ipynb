{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ac8fab7a-8fc5-eb41-58ca-ec3ad10e8c7b"
   },
   "source": [
    "## Two independed models for energy and class prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn two models separately and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras==2.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "3e9a2af5-0d48-7b2f-0271-c3574c1e368c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os, sys\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from random import shuffle\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(1)\n",
    "np.random.seed(37)\n",
    "random.seed(1254)\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e26ad680-b633-cd48-98b8-ea5459f4af37"
   },
   "source": [
    "### Get list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "d6aff428-8b5e-656c-409a-ce7de0e9143f"
   },
   "outputs": [],
   "source": [
    "folder1 = \"./data/idao_dataset/train/ER\"\n",
    "folder2 = \"./data/idao_dataset/train/NR\"\n",
    "\n",
    "imagefiles = [f for f in os.listdir(folder1) if os.path.isfile(os.path.join(folder1, f))]\n",
    "imagefiles_2 = [f for f in os.listdir(folder2) if os.path.isfile(os.path.join(folder2, f))]\n",
    "\n",
    "\n",
    "imagefiles.extend(imagefiles_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_and_int(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the brightest area of images for cropping (it was an experiment).For train data\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"ER\" in filename:\n",
    "        boolfolder = True\n",
    "    else:\n",
    "        boolfolder = False\n",
    "\n",
    "    if boolfolder:\n",
    "        image = cv2.imread(folder1 + \"/\" + filename)\n",
    "    else:\n",
    "        image = cv2.imread(folder2 + \"/\" + filename)\n",
    "    orig = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "    \n",
    "    return maxVal, maxLoc\n",
    "\n",
    "\n",
    "def get_point_and_int_inf(filename, link):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function finds the brightest area of images for cropping (it was an experiment).For test data/inference\n",
    "    \"\"\"\n",
    "    \n",
    "    image = cv2.imread(link + \"/\" + filename)\n",
    "\n",
    "    orig = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "    \n",
    "    return maxVal, maxLoc\n",
    "\n",
    "\n",
    "def sly_round(x):\n",
    "    \"\"\"\n",
    "    Round to the nearest energy class\n",
    "    \"\"\"\n",
    "    values = [1, 3, 6, 10, 20, 30]\n",
    "    \n",
    "    delta_values = [abs(x - i) for i in values]\n",
    "    return values[delta_values.index(min(delta_values))]\n",
    "    \n",
    "def math_round(x):\n",
    "    return sly_round(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "89898d6c-e0e8-55ea-dfdc-087545598961"
   },
   "source": [
    "### From imgs to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a2a5e7f4-9f65-482d-2d07-18057882c303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train_files: 13536\n",
      "1000 images in array\n",
      "2000 images in array\n",
      "3000 images in array\n",
      "4000 images in array\n",
      "5000 images in array\n",
      "6000 images in array\n",
      "7000 images in array\n",
      "8000 images in array\n",
      "9000 images in array\n",
      "10000 images in array\n",
      "11000 images in array\n",
      "12000 images in array\n",
      "13000 images in array\n",
      "All images to array!\n"
     ]
    }
   ],
   "source": [
    "train_files = []\n",
    "y_train = []\n",
    "y_train_class = []\n",
    "i = 0\n",
    "\n",
    "for _file in imagefiles:\n",
    "    train_files.append(_file)\n",
    "    label_in_file = _file.replace(\"__\", \"_\").replace(\"_He\", \"\").split(\"_\")\n",
    "    y_train.append(int(label_in_file[5]))\n",
    "    y_train_class.extend([0 if label_in_file[4] ==\"NR\" else 1 ])\n",
    "\n",
    "print(\"Files in train_files: {0}\".format(len(train_files)))\n",
    "\n",
    "\n",
    "image_width = 110\n",
    "image_height = 110\n",
    "\n",
    "channels = 1\n",
    "\n",
    "dataset = np.ndarray(shape=(len(train_files), image_height, image_width, channels),\n",
    "                     dtype=np.float32)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for _file in train_files:\n",
    "    \n",
    "    if \"ER\" in _file:\n",
    "        img = load_img(folder1 + \"/\" + _file) \n",
    "    elif \"NR\" in _file:\n",
    "        img = load_img(folder2 + \"/\" + _file) \n",
    "        \n",
    "    # Get the brightest area of image for cropping (not used now, just one of experiments)\n",
    "    #inten, (w, h) = get_point_and_int(_file)\n",
    "\n",
    "    \n",
    "    #load central part of image\n",
    "    img = img.crop((160, 160, 416, 416))\n",
    "    img.thumbnail((110, 110))\n",
    "\n",
    "    # To numpy array\n",
    "    \n",
    "    x = img_to_array(img)[:,:,0]  \n",
    "    \n",
    "    x =np.expand_dims(x, axis=2)\n",
    "\n",
    "    \n",
    "    x = (x - 128.0) / 128.0\n",
    "    dataset[i] = x\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(\"{0} images in array\".format(i))\n",
    "print(\"All images to array!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f0dd08a-0e8d-01e8-01ec-ba6026527586"
   },
   "source": [
    "### Splitting into training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6058479b-59f5-443b-60cc-ffc0581c660e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 10152, Val set size: 3215, Test set size: 169\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train, test_size=0.25, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.95, random_state=33)\n",
    "\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "4012328d-f63d-0f61-b5a6-f34661e8e32f"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "78a9c2ab-2ba4-8e65-ba44-d258c59a1d56"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3dc594db-2bf6-2791-493f-3233161047ac"
   },
   "source": [
    "### The First step CNN (Regresion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(110, 110, 1), activation='relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eskender/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/eskender/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/eskender/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2888: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model  = get_regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop if no progress more\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "#save checkpoints\n",
    "\n",
    "mcp_save = ModelCheckpoint('regr_model_best_st2_aug.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "#sheduler for decreasing lr\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "04c6092b-a23c-a8b7-f793-72a664b12f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "158/158 [==============================] - 103s - loss: 1.9099 - val_loss: 1.4822\n",
      "Epoch 2/50\n",
      "158/158 [==============================] - 103s - loss: 1.4130 - val_loss: 1.0282\n",
      "Epoch 3/50\n",
      "158/158 [==============================] - 103s - loss: 1.3446 - val_loss: 1.2159\n",
      "Epoch 4/50\n",
      "158/158 [==============================] - 102s - loss: 1.1970 - val_loss: 1.2775\n",
      "Epoch 5/50\n",
      "158/158 [==============================] - 102s - loss: 1.1294 - val_loss: 1.0826\n",
      "Epoch 6/50\n",
      "158/158 [==============================] - 105s - loss: 1.1244 - val_loss: 0.9142\n",
      "Epoch 7/50\n",
      "158/158 [==============================] - 103s - loss: 1.1017 - val_loss: 1.2626\n",
      "Epoch 8/50\n",
      "158/158 [==============================] - 102s - loss: 1.1642 - val_loss: 1.0176\n",
      "Epoch 9/50\n",
      "158/158 [==============================] - 103s - loss: 1.0395 - val_loss: 0.8616\n",
      "Epoch 10/50\n",
      "158/158 [==============================] - 103s - loss: 1.0322 - val_loss: 0.8124\n",
      "Epoch 11/50\n",
      "158/158 [==============================] - 103s - loss: 1.0049 - val_loss: 0.8624\n",
      "Epoch 12/50\n",
      "158/158 [==============================] - 103s - loss: 0.9719 - val_loss: 0.8723\n",
      "Epoch 13/50\n",
      "158/158 [==============================] - 107s - loss: 0.9623 - val_loss: 0.7695\n",
      "Epoch 14/50\n",
      "158/158 [==============================] - 103s - loss: 0.9482 - val_loss: 0.9124\n",
      "Epoch 15/50\n",
      "158/158 [==============================] - 102s - loss: 0.9344 - val_loss: 1.0452\n",
      "Epoch 16/50\n",
      "158/158 [==============================] - 101s - loss: 0.9489 - val_loss: 0.7523\n",
      "Epoch 17/50\n",
      "158/158 [==============================] - 102s - loss: 0.9776 - val_loss: 0.7438\n",
      "Epoch 18/50\n",
      "158/158 [==============================] - 102s - loss: 0.9216 - val_loss: 0.7553\n",
      "Epoch 19/50\n",
      "158/158 [==============================] - 100s - loss: 0.9384 - val_loss: 0.7448\n",
      "Epoch 20/50\n",
      "158/158 [==============================] - 100s - loss: 0.8998 - val_loss: 0.8101\n",
      "Epoch 21/50\n",
      "157/158 [============================>.] - ETA: 0s - loss: 0.9270\n",
      "Epoch 00020: reducing learning rate to 0.0005000000237487257.\n",
      "158/158 [==============================] - 100s - loss: 0.9274 - val_loss: 0.8816\n",
      "Epoch 22/50\n",
      "158/158 [==============================] - 100s - loss: 0.8336 - val_loss: 0.6532\n",
      "Epoch 23/50\n",
      "158/158 [==============================] - 100s - loss: 0.8484 - val_loss: 0.7446\n",
      "Epoch 24/50\n",
      "158/158 [==============================] - 99s - loss: 0.8315 - val_loss: 0.6531\n",
      "Epoch 25/50\n",
      "158/158 [==============================] - 99s - loss: 0.8391 - val_loss: 0.7203\n",
      "Epoch 26/50\n",
      "158/158 [==============================] - 99s - loss: 0.8232 - val_loss: 0.6455\n",
      "Epoch 27/50\n",
      "158/158 [==============================] - 99s - loss: 0.8474 - val_loss: 0.6382\n",
      "Epoch 28/50\n",
      "158/158 [==============================] - 99s - loss: 0.8092 - val_loss: 0.7056\n",
      "Epoch 29/50\n",
      "158/158 [==============================] - 100s - loss: 0.8034 - val_loss: 0.6228\n",
      "Epoch 30/50\n",
      "158/158 [==============================] - 101s - loss: 0.8231 - val_loss: 0.6146\n",
      "Epoch 31/50\n",
      "158/158 [==============================] - 101s - loss: 0.8108 - val_loss: 0.6161\n",
      "Epoch 32/50\n",
      "158/158 [==============================] - 100s - loss: 0.8110 - val_loss: 0.6260\n",
      "Epoch 33/50\n",
      "158/158 [==============================] - 100s - loss: 0.8101 - val_loss: 0.6268\n",
      "Epoch 34/50\n",
      "157/158 [============================>.] - ETA: 0s - loss: 0.8009\n",
      "Epoch 00033: reducing learning rate to 0.0002500000118743628.\n",
      "158/158 [==============================] - 101s - loss: 0.7997 - val_loss: 0.6249\n",
      "Epoch 35/50\n",
      "158/158 [==============================] - 100s - loss: 0.7682 - val_loss: 0.6333\n",
      "Epoch 36/50\n",
      "158/158 [==============================] - 100s - loss: 0.7949 - val_loss: 0.5841\n",
      "Epoch 37/50\n",
      "158/158 [==============================] - 100s - loss: 0.7666 - val_loss: 0.6261\n",
      "Epoch 38/50\n",
      "158/158 [==============================] - 99s - loss: 0.7693 - val_loss: 0.5832\n",
      "Epoch 39/50\n",
      "158/158 [==============================] - 99s - loss: 0.7710 - val_loss: 0.5997\n",
      "Epoch 40/50\n",
      "158/158 [==============================] - 99s - loss: 0.7622 - val_loss: 0.6398\n",
      "Epoch 41/50\n",
      "158/158 [==============================] - 99s - loss: 0.7590 - val_loss: 0.6534\n",
      "Epoch 42/50\n",
      "157/158 [============================>.] - ETA: 0s - loss: 0.7647\n",
      "Epoch 00041: reducing learning rate to 0.0001250000059371814.\n",
      "158/158 [==============================] - 100s - loss: 0.7656 - val_loss: 0.6345\n",
      "Epoch 43/50\n",
      "158/158 [==============================] - 102s - loss: 0.7361 - val_loss: 0.5737\n",
      "Epoch 44/50\n",
      "158/158 [==============================] - 101s - loss: 0.7213 - val_loss: 0.5588\n",
      "Epoch 45/50\n",
      "158/158 [==============================] - 101s - loss: 0.7397 - val_loss: 0.5725\n",
      "Epoch 46/50\n",
      "158/158 [==============================] - 102s - loss: 0.7352 - val_loss: 0.6045\n",
      "Epoch 47/50\n",
      "158/158 [==============================] - 104s - loss: 0.7477 - val_loss: 0.5809\n",
      "Epoch 48/50\n",
      "157/158 [============================>.] - ETA: 0s - loss: 0.7390\n",
      "Epoch 00047: reducing learning rate to 6.25000029685907e-05.\n",
      "158/158 [==============================] - 103s - loss: 0.7391 - val_loss: 0.5711\n",
      "Epoch 49/50\n",
      "158/158 [==============================] - 102s - loss: 0.7499 - val_loss: 0.5532\n",
      "Epoch 50/50\n",
      "158/158 [==============================] - 102s - loss: 0.7319 - val_loss: 0.5550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9ac0f3f90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=64), \n",
    "                    samples_per_epoch=len(X_train),  \n",
    "                    nb_epoch= 50, \n",
    "                    validation_data=val_datagen.flow(X_val, y_val, batch_size=16),\n",
    "                    nb_val_samples=len(X_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stop, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9aae9fb4-0771-5de3-024d-ca80d032c59f"
   },
   "source": [
    "### Test prediction and generation a part of submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"regr_model_best_st2_aug.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b0b59c59-de8c-919c-2f36-c225e8ac9369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/169 [===========================>..] - ETA: 0s\n",
      " Mean absolute error on test set: 0.47 \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"\\n Mean absolute error on test set: {0:.2f} \".format(model.evaluate(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(link):\n",
    "    \n",
    "    \"\"\"\n",
    "    Loading data from test\n",
    "    \"\"\"\n",
    "    \n",
    "    imagefiles = [f for f in os.listdir(link) if os.path.isfile(os.path.join(link, f))]\n",
    "\n",
    "    print(\"Files in directory: {}\".format(len(imagefiles)))\n",
    "\n",
    "    image_width = 110\n",
    "    image_height = 110\n",
    "\n",
    "    channels = 1\n",
    "\n",
    "    dataset = np.ndarray(shape=(len(imagefiles), image_height, image_width, channels),\n",
    "                         dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    for _file in imagefiles:\n",
    "\n",
    "        img = load_img(link + \"/\" + _file) \n",
    "\n",
    "        #inten, (w, h) = get_point_and_int_inf(_file, link)\n",
    "\n",
    "        img = img.crop((160, 160, 416, 416))\n",
    "\n",
    "        img.thumbnail((110, 110))\n",
    "\n",
    "        x = img_to_array(img)[:,:,0]  \n",
    "\n",
    "\n",
    "        x =np.expand_dims(x, axis=2)\n",
    "\n",
    "        # Normalize\n",
    "        x = (x - 128.0) / 128.0\n",
    "        dataset[i] = x\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{0} images to array\".format(i))\n",
    "    print(\"All images to array!\")\n",
    "    \n",
    "    return imagefiles, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 15058\n",
      "1000 images to array\n",
      "2000 images to array\n",
      "3000 images to array\n",
      "4000 images to array\n",
      "5000 images to array\n",
      "6000 images to array\n",
      "7000 images to array\n",
      "8000 images to array\n",
      "9000 images to array\n",
      "10000 images to array\n",
      "11000 images to array\n",
      "12000 images to array\n",
      "13000 images to array\n",
      "14000 images to array\n",
      "15000 images to array\n",
      "All images to array!\n",
      "Files in directory: 1502\n",
      "1000 images to array\n",
      "All images to array!\n"
     ]
    }
   ],
   "source": [
    "link_private = \"./data/idao_dataset/private_test\"\n",
    "link_public = \"./data/idao_dataset/public_test\"\n",
    "\n",
    "\n",
    "list_files_private, dataset_private = get_data(link_private)\n",
    "list_files_public, dataset_public = get_data(link_public)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_private = model.predict(dataset_private)\n",
    "predictions_public = model.predict(dataset_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pri = {'id': [i.replace(\".png\", \"\") for i in list_files_private],\n",
    "        'classification_predictions': 1, \n",
    "        'regression_predictions': [math_round(i[0]) for i in predictions_private ],\n",
    "        'is_public': 0,\n",
    "        'orig':[i[0] for i in predictions_private ]\n",
    "        \n",
    "       } \n",
    "df_pri = pd.DataFrame.from_dict(data_pri)\n",
    "\n",
    "\n",
    "data_pub = {'id': [i.replace(\".png\", \"\") for i in list_files_public],\n",
    "        'classification_predictions': 1, \n",
    "        'regression_predictions': [math_round(i[0]) for i in predictions_public ],\n",
    "        'is_public': 1,\n",
    "        'orig':[i[0] for i in predictions_public ] \n",
    "        \n",
    "       }\n",
    "\n",
    "df_pub = pd.DataFrame.from_dict(data_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "      <th>is_public</th>\n",
       "      <th>orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa9c74d71c591eedc4ce370c3b144eb9a23c8ba0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.014202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a02a0f55e306cf2a181fea35451611075a6f729</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20.636044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>488caca71da221550bddeeb9b1cbbf5de348d537</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19.560398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a01b6a560e0bdc54394289952a70058b9d849a82</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>19.981997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7b17af34c2fd0825819234e0bfc69dccd934809b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.074516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  classification_predictions  \\\n",
       "0  aa9c74d71c591eedc4ce370c3b144eb9a23c8ba0                           1   \n",
       "1  0a02a0f55e306cf2a181fea35451611075a6f729                           1   \n",
       "2  488caca71da221550bddeeb9b1cbbf5de348d537                           1   \n",
       "3  a01b6a560e0bdc54394289952a70058b9d849a82                           1   \n",
       "4  7b17af34c2fd0825819234e0bfc69dccd934809b                           1   \n",
       "\n",
       "   regression_predictions  is_public       orig  \n",
       "0                       1          1   1.014202  \n",
       "1                      20          1  20.636044  \n",
       "2                      20          1  19.560398  \n",
       "3                      20          1  19.981997  \n",
       "4                       3          1   3.074516  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pub.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pub.append(df_pri).drop(['is_public', 'orig'], axis=1).to_csv(\"sum1stage.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 10422, Val set size: 2492, Test set size: 622\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y_train_class, test_size=0.23, random_state=33)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.8, random_state=33)\n",
    "\n",
    "print(\"Train set size: {0}, Val set size: {1}, Test set size: {2}\".format(len(X_train), len(X_val), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rotation_range=90,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_datagen.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    AUC for Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(110, 110, 1), activation='relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('linear'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(1, activation='sigmoid'))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_classification_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "mcp_save = ModelCheckpoint('classif_model_best_st2_aug.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, epsilon=1e-4, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eskender/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/eskender/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 92s - loss: 0.5069 - auc: 0.6996 - val_loss: 0.3531 - val_auc: 0.8764\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 89s - loss: 0.2448 - auc: 0.9116 - val_loss: 0.1451 - val_auc: 0.9388\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 91s - loss: 0.1048 - auc: 0.9553 - val_loss: 0.0489 - val_auc: 0.9676\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 90s - loss: 0.0603 - auc: 0.9759 - val_loss: 0.0562 - val_auc: 0.9806\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 91s - loss: 0.0444 - auc: 0.9841 - val_loss: 0.0524 - val_auc: 0.9865\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 92s - loss: 0.0422 - auc: 0.9883 - val_loss: 0.0241 - val_auc: 0.9899\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 91s - loss: 0.1127 - auc: 0.9911 - val_loss: 0.1454 - val_auc: 0.9908\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 93s - loss: 0.0571 - auc: 0.9909 - val_loss: 0.0319 - val_auc: 0.9916\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 93s - loss: 0.0405 - auc: 0.9923 - val_loss: 0.0340 - val_auc: 0.9929\n",
      "Epoch 10/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0314 - auc: 0.9934\n",
      "Epoch 00009: reducing learning rate to 0.0005000000237487257.\n",
      "162/162 [==============================] - 90s - loss: 0.0314 - auc: 0.9934 - val_loss: 0.0259 - val_auc: 0.9938\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 90s - loss: 0.0227 - auc: 0.9943 - val_loss: 0.0164 - val_auc: 0.9947\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 91s - loss: 0.0299 - auc: 0.9950 - val_loss: 0.0352 - val_auc: 0.9952\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 91s - loss: 0.0210 - auc: 0.9954 - val_loss: 0.0176 - val_auc: 0.9957\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 91s - loss: 0.0195 - auc: 0.9959 - val_loss: 0.0148 - val_auc: 0.9961\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 91s - loss: 0.0252 - auc: 0.9963 - val_loss: 0.0151 - val_auc: 0.9965\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 91s - loss: 0.0197 - auc: 0.9967 - val_loss: 0.0169 - val_auc: 0.9968\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 91s - loss: 0.0249 - auc: 0.9969 - val_loss: 0.0172 - val_auc: 0.9970\n",
      "Epoch 18/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0227 - auc: 0.9971\n",
      "Epoch 00017: reducing learning rate to 0.0002500000118743628.\n",
      "162/162 [==============================] - 91s - loss: 0.0226 - auc: 0.9971 - val_loss: 0.0225 - val_auc: 0.9972\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 90s - loss: 0.0175 - auc: 0.9973 - val_loss: 0.0136 - val_auc: 0.9974\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 90s - loss: 0.0147 - auc: 0.9975 - val_loss: 0.0113 - val_auc: 0.9976\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 90s - loss: 0.0132 - auc: 0.9977 - val_loss: 0.0105 - val_auc: 0.9978\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 93s - loss: 0.0118 - auc: 0.9978 - val_loss: 0.0113 - val_auc: 0.9979\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 96s - loss: 0.0156 - auc: 0.9980 - val_loss: 0.0107 - val_auc: 0.9980\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 92s - loss: 0.0153 - auc: 0.9981 - val_loss: 0.0207 - val_auc: 0.9981\n",
      "Epoch 25/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0195 - auc: 0.9982\n",
      "Epoch 00024: reducing learning rate to 0.0001250000059371814.\n",
      "162/162 [==============================] - 92s - loss: 0.0194 - auc: 0.9982 - val_loss: 0.0108 - val_auc: 0.9982\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 92s - loss: 0.0144 - auc: 0.9983 - val_loss: 0.0095 - val_auc: 0.9983\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 99s - loss: 0.0140 - auc: 0.9984 - val_loss: 0.0112 - val_auc: 0.9984\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 94s - loss: 0.0111 - auc: 0.9984 - val_loss: 0.0120 - val_auc: 0.9985\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 98s - loss: 0.0123 - auc: 0.9985 - val_loss: 0.0095 - val_auc: 0.9986\n",
      "Epoch 30/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0118 - auc: 0.9986\n",
      "Epoch 00029: reducing learning rate to 6.25000029685907e-05.\n",
      "162/162 [==============================] - 96s - loss: 0.0118 - auc: 0.9986 - val_loss: 0.0117 - val_auc: 0.9986\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 93s - loss: 0.0102 - auc: 0.9986 - val_loss: 0.0102 - val_auc: 0.9987\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 94s - loss: 0.0101 - auc: 0.9987 - val_loss: 0.0116 - val_auc: 0.9987\n",
      "Epoch 33/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0112 - auc: 0.9988\n",
      "Epoch 00032: reducing learning rate to 3.125000148429535e-05.\n",
      "162/162 [==============================] - 93s - loss: 0.0112 - auc: 0.9988 - val_loss: 0.0111 - val_auc: 0.9988\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 92s - loss: 0.0117 - auc: 0.9988 - val_loss: 0.0087 - val_auc: 0.9988\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 97s - loss: 0.0094 - auc: 0.9989 - val_loss: 0.0091 - val_auc: 0.9989\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 93s - loss: 0.0097 - auc: 0.9989 - val_loss: 0.0089 - val_auc: 0.9989\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 94s - loss: 0.0100 - auc: 0.9989 - val_loss: 0.0088 - val_auc: 0.9990\n",
      "Epoch 38/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0103 - auc: 0.9990\n",
      "Epoch 00037: reducing learning rate to 1.5625000742147677e-05.\n",
      "162/162 [==============================] - 92s - loss: 0.0103 - auc: 0.9990 - val_loss: 0.0091 - val_auc: 0.9990\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 92s - loss: 0.0093 - auc: 0.9990 - val_loss: 0.0090 - val_auc: 0.9990\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 92s - loss: 0.0091 - auc: 0.9990 - val_loss: 0.0093 - val_auc: 0.9991\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 93s - loss: 0.0117 - auc: 0.9991 - val_loss: 0.0085 - val_auc: 0.9991\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 95s - loss: 0.0092 - auc: 0.9991 - val_loss: 0.0107 - val_auc: 0.9991\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 98s - loss: 0.0094 - auc: 0.9991 - val_loss: 0.0098 - val_auc: 0.9991\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 97s - loss: 0.0100 - auc: 0.9992 - val_loss: 0.0090 - val_auc: 0.9992\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 95s - loss: 0.0104 - auc: 0.9992 - val_loss: 0.0080 - val_auc: 0.9992\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 98s - loss: 0.0090 - auc: 0.9992 - val_loss: 0.0085 - val_auc: 0.9992\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 94s - loss: 0.0106 - auc: 0.9992 - val_loss: 0.0082 - val_auc: 0.9992\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 92s - loss: 0.0102 - auc: 0.9992 - val_loss: 0.0098 - val_auc: 0.9993\n",
      "Epoch 49/50\n",
      "161/162 [============================>.] - ETA: 0s - loss: 0.0102 - auc: 0.9993\n",
      "Epoch 00048: reducing learning rate to 7.812500371073838e-06.\n",
      "162/162 [==============================] - 93s - loss: 0.0102 - auc: 0.9993 - val_loss: 0.0085 - val_auc: 0.9993\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 93s - loss: 0.0108 - auc: 0.9993 - val_loss: 0.0087 - val_auc: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd9f9e8d050>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=64), \n",
    "                    samples_per_epoch=len(X_train),  \n",
    "                    nb_epoch=50, \n",
    "                    validation_data=val_datagen.flow(X_val, y_val, batch_size=16),\n",
    "                    nb_val_samples=len(X_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stop, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/622 [============================>.] - ETA: 0sAUC: 1.00\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"AUC: {0:.2f}\".format(model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: 15058\n",
      "1000 images to array\n",
      "2000 images to array\n",
      "3000 images to array\n",
      "4000 images to array\n",
      "5000 images to array\n",
      "6000 images to array\n",
      "7000 images to array\n",
      "8000 images to array\n",
      "9000 images to array\n",
      "10000 images to array\n",
      "11000 images to array\n",
      "12000 images to array\n",
      "13000 images to array\n",
      "14000 images to array\n",
      "15000 images to array\n",
      "All images to array!\n",
      "Files in directory: 1502\n",
      "1000 images to array\n",
      "All images to array!\n"
     ]
    }
   ],
   "source": [
    "list_files_private, dataset_private = get_data(link_private)\n",
    "list_files_public, dataset_public = get_data(link_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"classif_model_best_st2_aug.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_private = model.predict(dataset_private)\n",
    "predictions_public = model.predict(dataset_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pri_class = {'id': [i.replace(\".png\", \"\") for i in list_files_private],\n",
    "        'classification_predictions': [i[0] for i in  predictions_private], #[1 if i[0] >THRESHOLD   else 0 for i in predictions_private], \n",
    "        'regression_predictions': 1, \n",
    "                  'is_public': 0\n",
    "        \n",
    "       } \n",
    "df_pri_class = pd.DataFrame.from_dict(data_pri_class)\n",
    "\n",
    "\n",
    "data_pub_class = {'id': [i.replace(\".png\", \"\") for i in list_files_public],\n",
    "        'classification_predictions': [i[0] for i in predictions_public],#[1 if i[0] >THRESHOLD  else 0 for i in predictions_public],  \n",
    "        'regression_predictions': 1,\n",
    "                  'is_public': 1\n",
    "        \n",
    "       }\n",
    "\n",
    "\n",
    "df_pub_class = pd.DataFrame.from_dict(data_pub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_2 = df_pri_class.append(df_pub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_2.to_csv(\"sum2stage.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage_1 = pd.read_csv(\"sum1stage.csv\")\n",
    "df_stage_2 = pd.read_csv(\"sum2stage.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(\n",
    "         df_stage_2[['id', 'classification_predictions']], df_stage_1[['id', 'regression_predictions']], how=\"left\", \n",
    "         left_on=\"id\", right_on ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>classification_predictions</th>\n",
       "      <th>regression_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69de1a8b9c376ed67adc8913e3d79140480e2b60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07d6bc4eaf59ecdb54a77ac3ae7cc3e70523503b</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bc4f06d7e104d67b81346f9a15f40e75decfe129</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8e1b23a7ba7f13aa0a2e0adaaed4232bea9ee13d</td>\n",
       "      <td>0.020240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06bb5a1992e5c2bbd54530e15d8b4f6abf00746e</td>\n",
       "      <td>0.719759</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  classification_predictions  \\\n",
       "0  69de1a8b9c376ed67adc8913e3d79140480e2b60                    1.000000   \n",
       "1  07d6bc4eaf59ecdb54a77ac3ae7cc3e70523503b                    0.999954   \n",
       "2  bc4f06d7e104d67b81346f9a15f40e75decfe129                    0.998291   \n",
       "3  8e1b23a7ba7f13aa0a2e0adaaed4232bea9ee13d                    0.020240   \n",
       "4  06bb5a1992e5c2bbd54530e15d8b4f6abf00746e                    0.719759   \n",
       "\n",
       "   regression_predictions  \n",
       "0                       6  \n",
       "1                       3  \n",
       "2                       3  \n",
       "3                       1  \n",
       "4                      10  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"sumallstage.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 747,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
